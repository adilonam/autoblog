{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the SEO keywords and parent folder as input from the user\n",
    "seo_keywords = input(\"Enter SEO keywords: \")\n",
    "parent_folder = input(\"Enter parent folder name: \")\n",
    "# 1: moroccoheritage 2 : gobitcode\n",
    "website = input(\"Enter website number(1: moroccoheritage 2:gobitcode) : \")\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if website == '1':\n",
    "    file_path = f'./format/moroccoheritage.mdx'\n",
    "else:\n",
    "    file_path = f'./format/gobitcode.mdx'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    mdx_format = file.read()\n",
    "\n",
    "\n",
    "mdx_format = mdx_format.replace(\"current_date\", current_date)\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment variable\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "google_cx = os.getenv('GOOGLE_CX')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "title: Mastering Face Recognition with OpenCV and CNN\n",
      "date: '2024-11-12'\n",
      "tags: ['OpenCV', 'CNN', 'Face Recognition', 'Deep Learning', 'Computer Vision']\n",
      "draft: false\n",
      "summary: Learn how to implement a robust face recognition system using OpenCV and Convolutional Neural Networks (CNNs) in this comprehensive blog post.\n",
      "---\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Face recognition is a fundamental task in computer vision and has numerous applications in various fields, including security, law enforcement, and personal devices. With the advent of deep learning techniques, particularly Convolutional Neural Networks (CNNs), face recognition has become more accurate and efficient. In this blog post, we will explore how to master face recognition using OpenCV and CNNs.\n",
      "\n",
      "## Understanding Face Recognition\n",
      "\n",
      "Face recognition is a multi-step process that involves detecting faces in images or videos, extracting features from the detected faces, and matching these features to a database of known faces. There are two primary approaches to face recognition:\n",
      "\n",
      "1.  **Traditional Methods:** These methods rely on hand-crafted features, such as Eigenfaces, Fisherfaces, and Local Binary Patterns (LBP). While these methods are simple and efficient, they are less accurate than deep learning-based methods.\n",
      "2.  **Deep Learning-Based Methods:** These methods utilize CNNs to learn features from face images. CNNs are particularly effective for face recognition due to their ability to model complex patterns and relationships in image data.\n",
      "\n",
      "## OpenCV for Face Detection\n",
      "\n",
      "Before recognizing faces, we need to detect them in images or videos. OpenCV is a powerful computer vision library that provides a range of algorithms for face detection, including:\n",
      "\n",
      "*   **Haar Cascade Classifier:** A traditional method that uses Haar-like features and AdaBoost for face detection.\n",
      "*   **Deep Learning-Based Face Detection:** A more accurate method that utilizes CNNs for face detection.\n",
      "\n",
      "Here's an example of using OpenCV's Haar Cascade Classifier for face detection:\n",
      "\n",
      "```python\n",
      "import cv2\n",
      "\n",
      "# Load the Haar Cascade Classifier\n",
      "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
      "\n",
      "# Load the image\n",
      "img = cv2.imread('image.jpg')\n",
      "\n",
      "# Convert the image to grayscale\n",
      "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "# Detect faces\n",
      "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
      "\n",
      "# Draw rectangles around the detected faces\n",
      "for (x, y, w, h) in faces:\n",
      "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
      "\n",
      "# Display the output\n",
      "cv2.imshow('Face Detection', img)\n",
      "cv2.waitKey(0)\n",
      "cv2.destroyAllWindows()\n",
      "```\n",
      "\n",
      "## CNN-Based Face Recognition\n",
      "\n",
      "Once we have detected faces, we need to extract features from these faces and match them to a database of known faces. We can use a pre-trained CNN, such as the VGGFace2 model, for face recognition.\n",
      "\n",
      "Here's an example of using the VGGFace2 model for face recognition:\n",
      "\n",
      "```python\n",
      "import cv2\n",
      "from tensorflow.keras.applications import VGG16\n",
      "from tensorflow.keras.preprocessing import image\n",
      "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
      "import numpy as np\n",
      "\n",
      "# Load the VGGFace2 model\n",
      "model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
      "\n",
      "# Load the face detection model\n",
      "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
      "\n",
      "# Load the image\n",
      "img = cv2.imread('image.jpg')\n",
      "\n",
      "# Convert the image to grayscale\n",
      "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "# Detect faces\n",
      "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
      "\n",
      "# Extract features from the detected faces\n",
      "features = []\n",
      "for (x, y, w, h) in faces:\n",
      "    face = img[y:y+h, x:x+w]\n",
      "    face = cv2.resize(face, (224, 224))\n",
      "    face = image.img_to_array(face)\n",
      "    face = np.expand_dims(face, axis=0)\n",
      "    face = preprocess_input(face)\n",
      "    feature = model.predict(face)\n",
      "    feature = feature.flatten()\n",
      "    features.append(feature)\n",
      "\n",
      "# Compare the features to a database of known faces\n",
      "database = np.load('database.npy')\n",
      "distances = []\n",
      "for feature in features:\n",
      "    distances.append(np.linalg.norm(feature - database))\n",
      "index = np.argmin(distances)\n",
      "print('Identified Person:', index)\n",
      "```\n",
      "\n",
      "## Building a Face Recognition System\n",
      "\n",
      "To build a robust face recognition system, we need to consider several factors, including:\n",
      "\n",
      "*   **Face Detection:** Use a combination of traditional methods (e.g., Haar Cascade Classifier) and deep learning-based methods (e.g., SSD, Faster R-CNN) for face detection.\n",
      "*   **Face Alignment:** Use landmarks (e.g., eye centers, nose tip) to align faces and improve recognition accuracy.\n",
      "*   **Feature Extraction:** Use a pre-trained CNN (e.g., VGGFace2) to extract features from face images.\n",
      "*   **Matching:** Use a distance metric (e.g., Euclidean distance, cosine similarity) to match features to a database of known faces.\n",
      "\n",
      "Here's an example of building a face recognition system:\n",
      "\n",
      "```python\n",
      "import cv2\n",
      "from tensorflow.keras.applications import VGG16\n",
      "from tensorflow.keras.preprocessing import image\n",
      "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
      "import numpy as np\n",
      "import imutils\n",
      "\n",
      "class FaceRecognitionSystem:\n",
      "    def __init__(self, database):\n",
      "        self.database = database\n",
      "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
      "        self.model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
      "\n",
      "    def detect_faces(self, img):\n",
      "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
      "        faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
      "        return faces\n",
      "\n",
      "    def extract_features(self, face):\n",
      "        face = cv2.resize(face, (224, 224))\n",
      "        face = image.img_to_array(face)\n",
      "        face = np.expand_dims(face, axis=0)\n",
      "        face = preprocess_input(face)\n",
      "        feature = self.model.predict(face)\n",
      "        feature = feature.flatten()\n",
      "        return feature\n",
      "\n",
      "    def recognize_faces(self, features):\n",
      "        distances = []\n",
      "        for feature in features:\n",
      "            distances.append(np.linalg.norm(feature - self.database))\n",
      "        index = np.argmin(distances)\n",
      "        return index\n",
      "\n",
      "    def process_image(self, img):\n",
      "        faces = self.detect_faces(img)\n",
      "        features = []\n",
      "        for (x, y, w, h) in faces:\n",
      "            face = img[y:y+h, x:x+w]\n",
      "            feature = self.extract_features(face)\n",
      "            features.append(feature)\n",
      "        index = self.recognize_faces(features)\n",
      "        return index\n",
      "\n",
      "system = FaceRecognitionSystem(np.load('database.npy'))\n",
      "img = cv2.imread('image.jpg')\n",
      "index = system.process_image(img)\n",
      "print('Identified Person:', index)\n",
      "```\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "In this blog post, we explored the fundamentals of face recognition and how to master it using OpenCV and CNNs. We covered face detection, face alignment, feature extraction, and matching, and built a robust face recognition system. By following these steps, you can build your own face recognition system and apply it to various applications, such as security, law enforcement, and personal devices.\n",
      "\n",
      "## Ready to Master Face Recognition?\n",
      "\n",
      "Start building your own face recognition system today and become proficient in using OpenCV and CNNs for robust face recognition.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "client = Groq(api_key=groq_api_key)\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"You are a blog writer who write blog in this format: \\n {mdx_format} \\n Do not include any introductory text \"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Write a long-form blog about '{seo_keywords}' \"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=1024*3,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None,\n",
    ")\n",
    "# opencv cnn face recognition\n",
    "\n",
    "mdx_blog = \"\"\n",
    "\n",
    "for chunk in completion:\n",
    "    mdx_blog += chunk.choices[0].delta.content or \"\"\n",
    "\n",
    "print(mdx_blog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slug: mastering-face-recognition-with-opencv-and-cnn\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Function to generate a slug from the title\n",
    "def generate_slug(title):\n",
    "    # Convert to lowercase\n",
    "    slug = title.lower()\n",
    "    # Replace spaces and special characters with hyphens\n",
    "    slug = re.sub(r'[^a-z0-9]+', '-', slug)\n",
    "    # Remove leading and trailing hyphens\n",
    "    slug = slug.strip('-')\n",
    "    return slug\n",
    "\n",
    "\n",
    "# Regular expression to extract the title\n",
    "title_match = re.search(r'^title:\\s*(.*)$', mdx_blog, re.MULTILINE)\n",
    "\n",
    "if title_match:\n",
    "    title = title_match.group(1)\n",
    "    slug = generate_slug(title)\n",
    "else:\n",
    "    print(\"Title not found\")\n",
    "\n",
    "print(f\"Slug: {slug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_images_search import GoogleImagesSearch\n",
    "\n",
    "def download_images(keyword,path,  limit=1):\n",
    "    # You need to get your own API key and CX from Google Custom Search JSON API\n",
    "    gis = GoogleImagesSearch(google_api_key,google_cx)\n",
    "\n",
    "    search_params = {\n",
    "        'q': keyword,\n",
    "        'num': limit,\n",
    "        'safe': 'off',\n",
    "        'fileType': 'jpg|png',\n",
    "        'imgType': 'photo',\n",
    "        'imgSize': 'LARGE',  # Use a single size or remove this line if not needed\n",
    "        # 'imgDominantColor': 'black'  # Use a single color or remove this line if not needed\n",
    "    }\n",
    "\n",
    "    gis.search(search_params=search_params)\n",
    "    image = gis.results()[0]\n",
    "    image.download(f'./output/{path}')\n",
    "    image_name = os.path.basename(image.path)\n",
    "    return image_name\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "title: Mastering Face Recognition with OpenCV and CNN\n",
      "date: '2024-11-12'\n",
      "tags: ['OpenCV', 'CNN', 'Face Recognition', 'Deep Learning', 'Computer Vision']\n",
      "draft: false\n",
      "summary: Learn how to implement a robust face recognition system using OpenCV and Convolutional Neural Networks (CNNs) in this comprehensive blog post.\n",
      "---\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Face recognition is a fundamental task in computer vision and has numerous applications in various fields, including security, law enforcement, and personal devices. With the advent of deep learning techniques, particularly Convolutional Neural Networks (CNNs), face recognition has become more accurate and efficient. In this blog post, we will explore how to master face recognition using OpenCV and CNNs.\n",
      "\n",
      "## Understanding Face Recognition\n",
      "\n",
      "Face recognition is a multi-step process that involves detecting faces in images or videos, extracting features from the detected faces, and matching these features to a database of known faces. There are two primary approaches to face recognition:\n",
      "\n",
      "1.  **Traditional Methods:** These methods rely on hand-crafted features, such as Eigenfaces, Fisherfaces, and Local Binary Patterns (LBP). While these methods are simple and efficient, they are less accurate than deep learning-based methods.\n",
      "2.  **Deep Learning-Based Methods:** These methods utilize CNNs to learn features from face images. CNNs are particularly effective for face recognition due to their ability to model complex patterns and relationships in image data.\n",
      "\n",
      "## OpenCV for Face Detection\n",
      "\n",
      "Before recognizing faces, we need to detect them in images or videos. OpenCV is a powerful computer vision library that provides a range of algorithms for face detection, including:\n",
      "\n",
      "*   **Haar Cascade Classifier:** A traditional method that uses Haar-like features and AdaBoost for face detection.\n",
      "*   **Deep Learning-Based Face Detection:** A more accurate method that utilizes CNNs for face detection.\n",
      "\n",
      "Here's an example of using OpenCV's Haar Cascade Classifier for face detection:\n",
      "\n",
      "```python\n",
      "import cv2\n",
      "\n",
      "# Load the Haar Cascade Classifier\n",
      "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
      "\n",
      "# Load the image\n",
      "img = cv2.imread('image.jpg')\n",
      "\n",
      "# Convert the image to grayscale\n",
      "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "# Detect faces\n",
      "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
      "\n",
      "# Draw rectangles around the detected faces\n",
      "for (x, y, w, h) in faces:\n",
      "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
      "\n",
      "# Display the output\n",
      "cv2.imshow('Face Detection', img)\n",
      "cv2.waitKey(0)\n",
      "cv2.destroyAllWindows()\n",
      "```\n",
      "\n",
      "## CNN-Based Face Recognition\n",
      "\n",
      "Once we have detected faces, we need to extract features from these faces and match them to a database of known faces. We can use a pre-trained CNN, such as the VGGFace2 model, for face recognition.\n",
      "\n",
      "Here's an example of using the VGGFace2 model for face recognition:\n",
      "\n",
      "```python\n",
      "import cv2\n",
      "from tensorflow.keras.applications import VGG16\n",
      "from tensorflow.keras.preprocessing import image\n",
      "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
      "import numpy as np\n",
      "\n",
      "# Load the VGGFace2 model\n",
      "model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
      "\n",
      "# Load the face detection model\n",
      "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
      "\n",
      "# Load the image\n",
      "img = cv2.imread('image.jpg')\n",
      "\n",
      "# Convert the image to grayscale\n",
      "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "# Detect faces\n",
      "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
      "\n",
      "# Extract features from the detected faces\n",
      "features = []\n",
      "for (x, y, w, h) in faces:\n",
      "    face = img[y:y+h, x:x+w]\n",
      "    face = cv2.resize(face, (224, 224))\n",
      "    face = image.img_to_array(face)\n",
      "    face = np.expand_dims(face, axis=0)\n",
      "    face = preprocess_input(face)\n",
      "    feature = model.predict(face)\n",
      "    feature = feature.flatten()\n",
      "    features.append(feature)\n",
      "\n",
      "# Compare the features to a database of known faces\n",
      "database = np.load('database.npy')\n",
      "distances = []\n",
      "for feature in features:\n",
      "    distances.append(np.linalg.norm(feature - database))\n",
      "index = np.argmin(distances)\n",
      "print('Identified Person:', index)\n",
      "```\n",
      "\n",
      "## Building a Face Recognition System\n",
      "\n",
      "To build a robust face recognition system, we need to consider several factors, including:\n",
      "\n",
      "*   **Face Detection:** Use a combination of traditional methods (e.g., Haar Cascade Classifier) and deep learning-based methods (e.g., SSD, Faster R-CNN) for face detection.\n",
      "*   **Face Alignment:** Use landmarks (e.g., eye centers, nose tip) to align faces and improve recognition accuracy.\n",
      "*   **Feature Extraction:** Use a pre-trained CNN (e.g., VGGFace2) to extract features from face images.\n",
      "*   **Matching:** Use a distance metric (e.g., Euclidean distance, cosine similarity) to match features to a database of known faces.\n",
      "\n",
      "Here's an example of building a face recognition system:\n",
      "\n",
      "```python\n",
      "import cv2\n",
      "from tensorflow.keras.applications import VGG16\n",
      "from tensorflow.keras.preprocessing import image\n",
      "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
      "import numpy as np\n",
      "import imutils\n",
      "\n",
      "class FaceRecognitionSystem:\n",
      "    def __init__(self, database):\n",
      "        self.database = database\n",
      "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
      "        self.model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
      "\n",
      "    def detect_faces(self, img):\n",
      "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
      "        faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
      "        return faces\n",
      "\n",
      "    def extract_features(self, face):\n",
      "        face = cv2.resize(face, (224, 224))\n",
      "        face = image.img_to_array(face)\n",
      "        face = np.expand_dims(face, axis=0)\n",
      "        face = preprocess_input(face)\n",
      "        feature = self.model.predict(face)\n",
      "        feature = feature.flatten()\n",
      "        return feature\n",
      "\n",
      "    def recognize_faces(self, features):\n",
      "        distances = []\n",
      "        for feature in features:\n",
      "            distances.append(np.linalg.norm(feature - self.database))\n",
      "        index = np.argmin(distances)\n",
      "        return index\n",
      "\n",
      "    def process_image(self, img):\n",
      "        faces = self.detect_faces(img)\n",
      "        features = []\n",
      "        for (x, y, w, h) in faces:\n",
      "            face = img[y:y+h, x:x+w]\n",
      "            feature = self.extract_features(face)\n",
      "            features.append(feature)\n",
      "        index = self.recognize_faces(features)\n",
      "        return index\n",
      "\n",
      "system = FaceRecognitionSystem(np.load('database.npy'))\n",
      "img = cv2.imread('image.jpg')\n",
      "index = system.process_image(img)\n",
      "print('Identified Person:', index)\n",
      "```\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "In this blog post, we explored the fundamentals of face recognition and how to master it using OpenCV and CNNs. We covered face detection, face alignment, feature extraction, and matching, and built a robust face recognition system. By following these steps, you can build your own face recognition system and apply it to various applications, such as security, law enforcement, and personal devices.\n",
      "\n",
      "## Ready to Master Face Recognition?\n",
      "\n",
      "Start building your own face recognition system today and become proficient in using OpenCV and CNNs for robust face recognition.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Regex to match the <img> tag and capture the alt attribute\n",
    "img_tag_regex = r'<img[^>]*alt=\"([^\"]*)\"[^>]*>'\n",
    "\n",
    "# Find all matches\n",
    "matches = re.findall(img_tag_regex, mdx_blog)\n",
    "\n",
    "\n",
    "\n",
    "# Print the alt attributes\n",
    "for match in matches:\n",
    "    image_name =  download_images(match , parent_folder)\n",
    "    print(f\"alt attribute: {match}\")\n",
    "    new_src = f'/static/images/{parent_folder}/{image_name}'\n",
    "    mdx_blog = re.sub(rf'(<img[^>]*src=\")[^\"]*(\"[^>]*alt=\"{re.escape(match)}\"[^>]*>)', rf'\\1{new_src}\\2', mdx_blog)\n",
    "    \n",
    "print(mdx_blog) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File './output/mastering-face-recognition-with-opencv-and-cnn.mdx' created successfully.\n"
     ]
    }
   ],
   "source": [
    "filename = f\"./output/{slug}.mdx\"\n",
    "with open(filename, 'w') as file:\n",
    "    file.write(mdx_blog)\n",
    "\n",
    "print(f\"File '{filename}' created successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoblog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
